\section{Solution}

In this section, we present the identified research gaps, an overview of the proposed solution and the innovative aspects of this solution. The proposed solution aims to contribute to the application of Deep Reinforcement Learning (DRL) in Forex trading by addressing specific research gaps and introducing novel approaches to model architecture, training and optimisation techniques.

\subsection{Research Gaps}

Several research gaps have been identified through the review of the existing literature. Firstly, the application the Deep Deterministic Policy Gradient (DDPG) in Forex markets is underexplored. This gap is notable given the algorithm's potential advantages in handling continuous action spaces, which are particularly relevant for financial trading. Secondly, while Recurrent Neural Networks (RNN), especially Long-Short Term Memory (LSTM) networks, have shown efficacy in managing time-dependent data, their integration with DDPG, particularly in Forex trading, remains limited. Thirdly, there is a need to enhance the reward function from the commonly used total return to the sharpe ratio, which provides a more balanced measure by accounting for risk-adjusted returns. Furthermore, the application of online learning for real-time market adaptation is relatively unexplored. Finally, advanced risk and portfolio management techniques, such as variable position sizing within the DDPG framework, are areas that require further research.

\subsection{Proposed Solution}

The proposed solution addresses these gaps by developing a Forex trading system that integrates DDPG with an LSTM architecture, incorporates the sharpe ratio as the reward function, and supports online learning for continuous market adaptation. This approach aims to leverage the strengths of advanced DRL techniques to enhance trading performance and robustness.

\subsubsection{Model Innovation}

The application of DDPG to the Forex market represents a significant innovation in this field. DDPG is at the forefront of advancements in DRL algorithms, known for its ability to handle high-dimensional continuous action spaces effectively, making it particularly suitable for complex trading environments. Initially, the model will be tested with fixed position sizing. However, given DDPG's capability to support continuous action spaces, we will explore the potential of variable position sizing to enhance trading strategies. The initial implementation will utilize a vanilla FNN underneath the DDPG model. If time permits, we plan to integrate an RNN (LSTM) architecture due to its superiority in capturing sequential dependencies and temporal patterns, which are critical in financial time series analysis. Moreover, we will begin with the total return as the reward function but aim to test the sharpe ratio if feasible, due to its focus on risk-adjusted performance, offering a more comprehensive evaluation of trading strategies. This testing plan includes four configurations for both total return and sharpe ratio as reward functions totalling eight different models: DDPG with FNN and fixed position sizing, DDPG with FNN and variable position sizing, DDPG with RNN (LSTM) and fixed position sizing, and DDPG with RNN (LSTM) and variable position sizing. These configurations are expected to provide insight into the effectiveness and adaptability of the proposed solution in different trading scenarios.

\subsubsection{Training Innovation}

A key innovative aspect of the proposed solution is the direct integration with the cTrader platform \cite{noauthor_forex_nodate}, a prominent trading platform supported by many well-known brokers and a major competitor to MetaTrader4/5 \cite{noauthor_metatrader_nodate}. cTrader’s cross-broker compatibility allows researchers to select brokers that best align with their requirements, such as commission rates, swaps, and spreads. This project proposes building a server in .NET and a client in Python, where the server handles data feeds and trading operations (e.g., opening, modifying, and closing positions), and the client processes these feeds and sends back trading decisions. This setup enables online training, a superior technique that closely simulates live trading conditions, allowing the model to adapt to real-time market changes. In addition, it facilitates visual backtesting of strategies and seamless deployment in live trading contexts. This approach aims to combine the robustness of cTrader’s infrastructure with the flexibility and analytical capabilities of Python, allowing accurate performance results that account for real explicit and implicit costs.

\subsubsection{Optimization Innovation}

The proposed solution introduces several innovative optimisation techniques to improve the convergence and generalisation power of the model. We will start by testing the model on an hourly timeframe, an underexplored area, and, if feasible, extend the testing to a daily timeframe. The state space will be enriched with technical analysis components in addition to OHLCV data, in order to provide a comprehensive view of market conditions and achieve the Markov property, which is essential for effective reinforcement learning. All features will undergo rigorous engineering; we plan to apply normalisation techniques to standardise the data, making it easier for the neural networks to process and learn effectively. Regularisation techniques and adaptive learning rates will be used in neural network models to mitigate bias-variance issues, enhancing the generalisation capabilities of the model. In the reinforcement learning models, we will utilise \(\varepsilon\)-greedy policies and Gaussian noise to balance exploration and exploitation, encouraging the discovery of optimal trading strategies while leveraging known profitable actions. These optimisation strategies are designed to enhance the model's performance, stability and adaptability, ensuring it can effectively navigate the complexities of the Forex market.